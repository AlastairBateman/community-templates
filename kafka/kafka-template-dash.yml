apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: goofy-poincare-7c4001
spec:
    color: '#8e1fc3'
    name: kafka
---
apiVersion: influxdata.com/v2alpha1
kind: Dashboard
metadata:
    name: boring-dewdney-3c4001
spec:
    associations:
      - kind: Label
        name: goofy-poincare-7c4001
    charts:
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: Controller State
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_controller")
                  |> filter(fn: (r) => r["_field"] == "ControllerState")
        width: 2
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Fetch Requests Per Topic Per Second
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_topics")
                  |> filter(fn: (r) => r["_field"] == "TotalFetchRequestsPerSec")
                  |> group(columns: ["topic"])
        width: 4
        xCol: _time
        yCol: _value
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: ZK Latency
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "zookeeper")
                  |> filter(fn: (r) => r["_field"] == "max_latency" or r["_field"] == "min_latency" or r["_field"] == "avg_latency")
        width: 4
        xCol: _time
        yCol: _value
        yPos: 4
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 2
        height: 1
        kind: Single_Stat
        name: Active Controller Count
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_controller")
                  |> filter(fn: (r) => r["_field"] == "ActiveControllerCount")
                  |> group()
        width: 2
        xPos: 2
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: Underreplicated Partitions (total)
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_partition")
                  |> filter(fn: (r) => r["_field"] == "UnderReplicatedPartitions")
                  |> last()
                  |> group()
                  |> sum()
        width: 2
        xPos: 4
      - axes:
          - base: "2"
            label: Bytes
            name: y
            scale: linear
          - base: "10"
            name: x
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Bytes Per Minute Per Broker
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_requests")
                  |> filter(fn: (r) => r["_field"] == "BytesCount")
                  |> window(every: 1m)
                  |> derivative(unit: 1m, nonNegative: true, columns: ["_value"], timeColumn: "_time")
                  |> group(columns: ["host"])
                  |> sort(columns: ["_time"])
        shade: true
        width: 4
        xCol: _time
        xPos: 4
        yCol: _value
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: ZK Alive Connections
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "zookeeper")
                  |> filter(fn: (r) => r["_field"] == "num_alive_connections")
        width: 4
        xCol: _time
        xPos: 4
        yCol: _value
        yPos: 4
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: Underreplicated Partitions in v.kafka_topic
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_partition")
                  |> filter(fn: (r) => r["_field"] == "UnderReplicatedPartitions")
                  |> filter(fn: (r) => r.topic == v.kafka_topic)
                  |> last()
        width: 2
        xPos: 6
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 0
        height: 1
        kind: Single_Stat
        name: LogEndOffset in v.kafka_topic
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_partition")
                  |> filter(fn: (r) => r["_field"] == "LogEndOffset")
                  |> filter(fn: (r) => r.topic == v.kafka_topic)
        width: 4
        xPos: 8
      - axes:
          - base: "10"
            name: y
            scale: linear
          - base: "10"
            name: x
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Bytes per broker / min
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_requests")
                  |> filter(fn: (r) => r["_field"] == "BytesCount")
                  |> window(every: 1m)
                  |> derivative(unit: 1m, nonNegative: true, columns: ["_value"], timeColumn: "_time")
                  |> group(columns: ["host"])
                  |> sort(columns: ["_time"])
          - query: |-
                from(bucket: "sam's Bucket")
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_requests")
                  |> filter(fn: (r) => r["_field"] == "BytesMax")
        width: 4
        xCol: _time
        xPos: 8
        yCol: _value
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "2"
            name: y
            scale: linear
        colors:
          - hex: '#31C0F6'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#A500A5'
            name: Nineteen Eighty Four
            type: scale
          - hex: '#FF7E27'
            name: Nineteen Eighty Four
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Errors per request
        position: overlaid
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r["_measurement"] == "kafka_network")
                  |> filter(fn: (r) => r._field != "NONE")
                  |> group(columns: ["request"])
                  |> sort(columns: ["_time"])
                  |> derivative(unit: 1s, nonNegative: true, columns: ["_value"], timeColumn: "_time")
        width: 4
        xCol: _time
        xPos: 8
        yCol: _value
        yPos: 4
    name: Kafka Metrics

---
apiVersion: influxdata.com/v2alpha1
kind: Telegraf
metadata:
    name: kafka-metrics-28052019
spec:
    name: kafka-metrics
    config: |
      [agent]

        interval = "10s"
        round_interval = true
        metric_batch_size = 1000
        metric_buffer_limit = 1000
        collection_jitter = "0s"
        flush_interval = "10s"
        flush_jitter = "0s"
        precision = ""
        debug = true
        quiet = false
        logfile = ""
        hostname = ""
        omit_hostname = false

      ###############################################################################
      #                            INPUT PLUGINS                                    #
      ###############################################################################

      [[outputs.influxdb_v2]]

        urls = ["$INFLUX_HOST"]
        # urls = ["https://enb37b16zawnc.x.pipedream.net"]
        token = "$INFLUX_TOKEN"
        organization = "$INFLUX_ORG"
        bucket = "$INFLUX_BUCKET"

      # [[outputs.file]]



      ###############################################################################
      #                            INPUT PLUGINS                                    #
      ###############################################################################

      # for more info on input plugins: https://github.com/influxdata/telegraf/tree/master/plugins/inputs

      [[inputs.cpu]]
      [[inputs.mem]]
      [[inputs.disk]]
      [[inputs.diskio]]
      [[inputs.net]]
      [[inputs.kernel]]
      [[inputs.swap]]
      [[inputs.processes]]

      [[inputs.zookeeper]]

      [[inputs.jolokia2_agent]]
        default_tag_prefix = ""
        default_field_prefix = ""
        default_field_separator = "_"
        urls = ["$JOLOKIA_AGENT_URL"]
        tagexclude = ["jolokia_agent_url"]

        # kafka.server
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=*"
          paths        = ["Count"]
          field_name = "$1"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=PartitionCount"
          field_name   = "PartitionCount"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=LeaderCount"
          field_name   = "LeaderCount"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_replica_manager"
          mbean        = "kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions"
          field_name   = "UnderReplicatedPartitions"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=kafka-metrics-count"
          field_name   = "kafka_metrics_count"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=BrokerTopicMetrics,name=*"
          field_name   = "kafka_metrics_count"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=DelayedOperationPurgatory,name=NumDelayedOperations,delayedOperation=*"
          field_name   = "$1"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_broker"
          mbean        = "kafka.server:type=Produce"
          field_name   = "ProduceQueueSize"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_topics"
          mbean        = "kafka.server:type=BrokerTopicMetrics,name=*,topic=*"
          paths        = ["Count"]
          field_name   = "$1"
          tag_keys     = ["topic"]
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_controller"
          mbean        = "kafka.controller:type=KafkaController,name=*"
          field_name   = "$1"

        # kafka.network
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_network"
          mbean        = "kafka.network:type=RequestMetrics,name=ErrorsPerSec,request=*,error=*"
          paths        = ["Count"]
          tag_keys     = ["request"]
          field_name   = "$2"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_requests"
          mbean        = "kafka.network:type=RequestMetrics,name=RequestBytes,request=*"
          tag_keys     = ["request"]
          field_prefix = "Bytes"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_requests"
          mbean        = "kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request=*"
          tag_keys     = ["request"]
          field_prefix = "QueueTime"
        [[inputs.jolokia2_agent.metric]]
          name         = "kafka_requests"
          mbean        = "kafka.network:type=RequestMetrics,name=RequestsPerSec,request=*,version=*"
          tag_keys     = ["request"]
          paths        = ["Count"]
          field_name   = "Count"

        # kafka.log
        [[inputs.jolokia2_agent.metric]]
          name       = "kafka_partition"
          mbean      = "kafka.log:name=*,partition=*,topic=*,type=Log"
          field_name = "$1"
          tag_keys   = ["topic", "partition"]

        # kafka.cluster
        [[inputs.jolokia2_agent.metric]]
          name       = "kafka_partition"
          mbean      = "kafka.cluster:name=UnderReplicated,partition=*,topic=*,type=Partition"
          field_name = "UnderReplicatedPartitions"
          tag_keys   = ["topic"]

